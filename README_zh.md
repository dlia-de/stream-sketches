# Stream Sketches â€” ç‚¹å‡»æµçš„ UV ä¸ Top-Nï¼ˆSpark + Parquet + DuckDBï¼‰

ä¸€ä¸ªæœ¬åœ°å³å¯å¤ç°çš„ç‚¹å‡»æµå°ç³»ç»Ÿï¼š
- ç”Ÿæˆå™¨æŒç»­å†™å…¥ JSON/JSONL äº‹ä»¶ï¼›
- æµå¼ä½œä¸šåœ¨ 10 ç§’çª—å£å†…ç”¨ **HLL++** è¿‘ä¼¼å»é‡è®¡ç®— **UV**ï¼Œä»¥ **append** æ–¹å¼å†™ **Parquet**ï¼›
- æ‰¹å¤„ç†è„šæœ¬è®¡ç®— **Top-N é¡µé¢**ï¼ˆç»ˆç«¯æ‰“å°å¹¶å†™ Parquetï¼‰ã€‚

é»˜è®¤è¾“å…¥ä¸ºæ–‡ä»¶ç›®å½•ï¼›åç»­å¯åˆ‡æ¢åˆ° **Kafka**ã€‚é«˜çº§åŠŸèƒ½ **CMS/Bloom** è§„åˆ’ä¸­ã€‚

## æ¶æ„
    Generator  -->  data/input_stream/ (JSON/JSONL)
                      |
                      v
    streaming_uv.py  [Structured Streaming]
      - ts -> event_time (timestamp)
      - window = 10s, watermark = 10s
      - approx_count_distinct(uid) -> UV
      - append Parquet + checkpoint -> data/stream_agg/
                      |
                      v
    batch_topn.py  (æ‰¹å¤„ç†)
      - groupBy(page).count().orderBy desc -> Top-N
      - ç»ˆç«¯æ‰“å° + å†™ Parquet -> data/batch_topn/

## å¿«é€Ÿå¼€å§‹
    python scripts/generate_clickstream.py        # äº‹ä»¶ç”Ÿæˆå™¨
    spark-submit jobs/streaming_uv.py             # æµå¼ UVï¼ˆHLL++ï¼‰
    spark-submit jobs/batch_topn.py               # æ‰¹å¤„ç† Top-N
    # Spark UI: http://localhost:4040

æˆªå›¾ï¼ˆæ”¾åˆ° `docs/screenshots/`ï¼‰
- `day0_stream_ui.png` â€”â€” æµå¼ UI é¡µé¢
- `day0_batch_topn.png` â€”â€” æ‰¹å¤„ç† Top-N è¾“å‡º

DuckDB æ ¡éªŒï¼ˆå¯é€‰ï¼‰
    duckdb -c "SELECT * FROM parquet_scan('data/stream_agg/*.parquet') LIMIT 20;"
    duckdb -c "SELECT * FROM parquet_scan('data/batch_topn/*.parquet') ORDER BY count DESC LIMIT 5;"

## æ•°æ®æ¨¡å‹
- `uid STRING` â€”â€” ç”¨æˆ·æ ‡è¯†ï¼ˆæ¼”ç¤ºä¸ºéšæœºï¼‰
- `page STRING` â€”â€” URL è·¯å¾„
- `ts LONG` â€”â€” äº‹ä»¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

## ä»“åº“ç»“æ„
    scripts/                 # ç”Ÿæˆå™¨
    jobs/                    # æµå¼ä¸æ‰¹å¤„ç†
    data/                    # ç”Ÿæˆæ•°æ®ï¼ˆgit å¿½ç•¥ï¼‰
      input_stream/
      stream_agg/
    chk/                     # checkpointï¼ˆgit å¿½ç•¥ï¼‰
    docs/screenshots/        # README æˆªå›¾

## è®¾è®¡å–èˆ
- **æ–‡ä»¶æº + Parquet**ï¼šWindows ä¸Šæœ€ç¨³ï¼›Parquet ä¾¿äº DuckDB æœ¬åœ°æ ¸å¯¹ã€‚
- **HLL++ï¼ˆapprox_count_distinctï¼‰**ï¼šä½å†…å­˜ã€è¿‘ä¼¼å»é‡ï¼Œå…é¢å¤–ä¾èµ–ã€‚
- **append + watermark**ï¼šæ–‡ä»¶ç±» sink ä¸æ”¯æŒ `complete`ï¼Œåªè¾“å‡ºâ€œå°å£â€çš„çª—å£ã€‚
- **JSONL**ï¼šæŒ‰ç§’æ»šåŠ¨çš„ .jsonl å¯å‡å°‘å°æ–‡ä»¶æ•°é‡ã€‚

## å½“å‰è¿›åº¦
- âœ… æµå¼ UVï¼ˆHLL++ï¼‰â†’ Parquetï¼ˆappend + checkpointï¼‰
- âœ… æ‰¹å¤„ç† Top-Nï¼ˆæ‰“å° + Parquetï¼‰
- ğŸŸ¡ æµå¼ Top-Nï¼ˆè¿›è¡Œä¸­ï¼‰
- ğŸŸ¡ CMS / Bloomï¼ˆé«˜çº§è®¡åˆ’ï¼‰
- ğŸŸ¡ Kafka æºï¼ˆè®¡åˆ’ï¼Œå¯æ›¿æ¢æ–‡ä»¶æºï¼‰

## å­¦åˆ°çš„è¦ç‚¹
- Windows ä¸Šæ–‡ä»¶ sink å¿…é¡» **append + watermark**ï¼›`complete` ä¼šæŠ¥é”™ã€‚
- Structured Streaming ä¸€å®šä¼šè¯»å†™ **checkpoint**ï¼Œä¸è¦çº³å…¥ gitã€‚
- éœ€è¦åŒ¹é…ç‰ˆæœ¬çš„ Hadoop åŸç”Ÿåº“ï¼ˆwinutils/hadoop.dllï¼‰ï¼Œæˆ–æ”¹ç”¨ WSL2ã€‚
- Demo ç”¨çŸ­çª—å£ï¼ˆ10sï¼‰æ›´å®¹æ˜“çœ‹åˆ°ç»“æœã€‚
- Parquet + DuckDB é€‚åˆæœ¬åœ°å¿«é€Ÿæ ¡éªŒä¸é¢è¯•æ¼”ç¤ºã€‚
